# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_embedding.ipynb.

# %% auto 0
__all__ = ['download_embedding_model', 'load_embedding_model', 'embed_text', 'embedding_system', 'get_embeddings', 'pdf_to_text',
           'get_pdfs_from_folder', 'embed_category_papers']

# %% ../nbs/03_embedding.ipynb 3
import chromadb
import cohere
import os
import torch
from chromadb.errors import IDAlreadyExistsError
from functools import cache 
from pypdf import PdfReader
from .arxiv_categories import exists
from .arxiv_sync import get_docs_path
from rich import print
from rich.progress import Progress
from transformers import AutoTokenizer, AutoModel

# %% ../nbs/03_embedding.ipynb 5
def download_embedding_model(model_path: str, model_name: str):
    """Download a Hugging Face model and tokenizer to the specified directory"""
    # Check if the directory already exists
    if not os.path.exists(model_path):
        os.makedirs(model_path)
    else:
        return

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)

    # Save the model and tokenizer to the specified directory
    model.save_pretrained(model_path)
    tokenizer.save_pretrained(model_path)

# %% ../nbs/03_embedding.ipynb 10
@cache
def load_embedding_model(model_path: str):
    """Load a Hugging Face model and tokenizer from the specified directory"""
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModel.from_pretrained(model_path)
    return model, tokenizer

# %% ../nbs/03_embedding.ipynb 15
def embed_text(text: str, model, tokenizer):
    """Embed a text using a Hugging Face model and tokenizer"""
    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')

    # Compute token embeddings
    with torch.no_grad():
        model_output = model(**encoded_input)
        # Perform pooling. In this case, cls pooling.
        sentence_embeddings = model_output[0][:, 0]

    embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)

    return embeddings

# %% ../nbs/03_embedding.ipynb 20
def embedding_system() -> str:
    """Return a unique identifier for the embedding system currently in use"""

    if os.environ.get('EMBEDDING_SYSTEM') == 'BAAI/bge-base-en':
        return 'baai-bge-base-en'
    elif os.environ.get('EMBEDDING_SYSTEM') == 'cohere':
        return 'cohere'
        embeddings = co.embed([text]).embeddings
    else:
        return ''

# %% ../nbs/03_embedding.ipynb 22
def get_embeddings(text: str) -> list:
    """Get embeddings for a text using any supported embedding system."""

    match embedding_system():
        case 'baai-bge-base-en':
            model, tokenizer = load_embedding_model(os.environ.get('MODELS_PATH'))
            return embed_text(text, model, tokenizer).tolist()
        case 'cohere':
            co = cohere.Client(os.environ.get('COHERE_API_KEY'))
            return co.embed([text]).embeddings
        case other:
            return []

# %% ../nbs/03_embedding.ipynb 24
def pdf_to_text(file_path: str) -> str:
    """Read a PDF file and output it as a text string."""
    with open(file_path, 'rb') as pdf_file_obj:
        pdf_reader = PdfReader(pdf_file_obj)
        text = ''

        for page in pdf_reader.pages:
            text += page.extract_text()

        return text

# %% ../nbs/03_embedding.ipynb 28
def get_pdfs_from_folder(folder_path: str) -> list:
    """Given a folder path, return all the PDF files existing in that folder."""
    pdfs = []

    for pdf in os.listdir(folder_path):
        if pdf.endswith(".pdf"):
            pdfs.append(pdf)

    return pdfs

# %% ../nbs/03_embedding.ipynb 34
def embed_category_papers(category: str) -> bool:
    """Given a ArXiv category, create the embeddings for each of the PDF paper existing locally.
    Embeddings is currently using Cohere's embedding service.
    Returns True if successful, False otherwise."""
 
    chroma_client = chromadb.PersistentClient(path=os.environ.get('CHROMA_DB_PATH'))

    if exists(category):
        # We create two Chroma collection of embeddings:
        #   1. a general one with all and every embeddings called 'all'
        #   2. one for the specific ArXiv category
        papers_all_collection = chroma_client.get_or_create_collection(name="all_" + embedding_system())
        papers_category_collection = chroma_client.get_or_create_collection(name="arxiv_" + category + '_' + embedding_system())

        with Progress() as progress:
            folder_path = get_docs_path(category)
            pdfs = get_pdfs_from_folder(folder_path)

            task = progress.add_task("[cyan]Embedding papers...", total=len(pdfs))

            for pdf in pdfs:
                # check if the PDF file has already been embedded and indexed in Chromadb,
                # let's not do all this processing if that is the case.
                check_pdf = papers_all_collection.get(ids=[pdf])

                if not progress.finished:
                    progress.update(task, advance=1)

                if len(check_pdf['ids']) == 0:
                    doc = pdf_to_text(folder_path.rstrip('/') + '/' + pdf)

                    try:
                        papers_all_collection.add(
                            embeddings=get_embeddings(doc),
                            documents=[doc.encode("unicode_escape").decode()], # necessary escape to prevent possible encoding errors when adding to Chroma
                            metadatas=[{"source": pdf,
                                        "category": category}],
                            ids=[pdf]
                        )
                    except IDAlreadyExistsError:
                        print("[yellow]ID already existing in Chroma DB, skipping...[/yellow]")
                        continue
                        
                    try:
                        papers_category_collection.add(
                            embeddings=get_embeddings(doc),
                            documents=[doc.encode("unicode_escape").decode()], # necessary escape to prevent possible encoding errors when adding to Chroma
                            metadatas=[{"source": pdf}],
                            ids=[pdf]
                        )
                    except IDAlreadyExistsError:
                        print("[yellow]ID already existing in Chroma DB, skipping...[/yellow]")
                        continue
        return True
    else:
        print("[red]Can't persist embeddings in local vector db, ArXiv category not existing[/red]")
        return False
