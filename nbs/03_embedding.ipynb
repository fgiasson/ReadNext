{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "ReadNext currently uses Cohere's embedding web service to generate the embedding of each of the arXiv paper. We will eventually extend that to other services, including some local ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import chromadb\n",
    "import cohere\n",
    "import os\n",
    "from chromadb.errors import IDAlreadyExistsError\n",
    "from pypdf import PdfReader\n",
    "from readnext.arxiv_categories import exists\n",
    "from readnext.arxiv_sync import get_docs_path\n",
    "from rich import print\n",
    "from rich.progress import Progress\n",
    "\n",
    "# TODO Default embedding to use BGE via Hugging Face: https://blog.gopenai.com/bge-embeddings-langchain-and-chroma-for-retrieval-qa-9c684206d8f3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF to Text\n",
    "\n",
    "The library PdfReader is used to extract the text from the PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def pdf_to_text(file_path: str) -> str:\n",
    "    \"\"\"Read a PDF file and output it as a text string.\"\"\"\n",
    "    pdf_file_obj = open(file_path, 'rb')\n",
    "    pdf_reader = PdfReader(pdf_file_obj)\n",
    "    text = ''\n",
    "\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pdf_to_text(\"../tests/assets/test.pdf\") == \"this is a test\"\n",
    "assert pdf_to_text(\"../tests/assets/test.pdf\") != \"this is a test foo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PDF files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_pdfs_from_folder(folder_path: str) -> list:\n",
    "    \"\"\"Given a folder path, return all the PDF files existing in that folder.\"\"\"\n",
    "    pdfs = []\n",
    "\n",
    "    for pdf in os.listdir(folder_path):\n",
    "        if pdf.endswith(\".pdf\"):\n",
    "            pdfs.append(pdf)\n",
    "\n",
    "    return pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_pdfs_from_folder(\"../tests/assets/\") == ['test.pdf']\n",
    "assert get_pdfs_from_folder(\"../tests/assets/\") != ['test.pdf', 'foo.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed all papers of a arXiv category\n",
    "\n",
    "The embedding database management system ReadNext uses is [Chroma](https://www.trychroma.com/).\n",
    "\n",
    "The embedding DBMS is organized as follows:\n",
    "\n",
    " - Each category (sub or top categories) become a collection of embeddings\n",
    " - We have one global collection named `all` that contains all the embeddings of every known categories\n",
    "\n",
    "When a new arXiv category is being processing, all the embeddings of the papers it contains will be added to the collection related to its category, and to the global collection.\n",
    "\n",
    "For the category collection, we have to prefix each category with `_arxiv` to avoid the restriction that Chroma won't accept a collection name with less than three characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def embed_category_papers(category: str) -> bool:\n",
    "    \"\"\"Given a ArXiv category, create the embeddings for each of the PDF paper existing locally.\n",
    "    Embeddings is currently using Cohere's embedding service.\n",
    "    Returns True if successful, False otherwise.\"\"\"\n",
    "\n",
    "    co = cohere.Client(os.environ.get('COHERE_API_KEY'))\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=os.environ.get('CHROMA_DB_PATH'))\n",
    "\n",
    "    if exists(category):\n",
    "        # We create two Chroma collection of embeddings:\n",
    "        #   1. a general one with all and every embeddings called 'all'\n",
    "        #   2. one for the specific ArXiv category\n",
    "        papers_all_collection = chroma_client.get_or_create_collection(name=\"all\")\n",
    "        papers_category_collection = chroma_client.get_or_create_collection(name=\"arxiv_\" + category)\n",
    "\n",
    "        with Progress() as progress:\n",
    "            folder_path = get_docs_path(category)\n",
    "            pdfs = get_pdfs_from_folder(folder_path)\n",
    "\n",
    "            task = progress.add_task(\"[cyan]Embedding papers...\", total=len(pdfs))\n",
    "\n",
    "            for pdf in pdfs:\n",
    "                # check if the PDF file has already been embedded and indexed in Chromadb,\n",
    "                # let's not do all this processing if that is the case.\n",
    "                check_pdf = papers_all_collection.get(ids=[pdf])\n",
    "\n",
    "                if not progress.finished:\n",
    "                    progress.update(task, advance=1)\n",
    "\n",
    "                if len(check_pdf['ids']) == 0:\n",
    "                    doc = pdf_to_text(folder_path.rstrip('/') + '/' + pdf)\n",
    "\n",
    "                    # get the embedding of the paper from Cohere\n",
    "                    embedding = co.embed([doc])\n",
    "\n",
    "                    try:\n",
    "                        papers_all_collection.add(\n",
    "                            embeddings=embedding.embeddings,\n",
    "                            documents=[doc.encode(\"unicode_escape\").decode()], # necessary escape to prevent possible encoding errors when adding to Chroma\n",
    "                            metadatas=[{\"source\": pdf,\n",
    "                                        \"category\": category}],\n",
    "                            ids=[pdf]\n",
    "                        )\n",
    "                    except IDAlreadyExistsError:\n",
    "                        print(\"[yellow]ID already existing in Chroma DB, skipping...[/yellow]\")\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        papers_category_collection.add(\n",
    "                            embeddings=embedding.embeddings,\n",
    "                            documents=[doc.encode(\"unicode_escape\").decode()], # necessary escape to prevent possible encoding errors when adding to Chroma\n",
    "                            metadatas=[{\"source\": pdf}],\n",
    "                            ids=[pdf]\n",
    "                        )\n",
    "                    except IDAlreadyExistsError:\n",
    "                        print(\"[yellow]ID already existing in Chroma DB, skipping...[/yellow]\")\n",
    "                        continue\n",
    "        return True\n",
    "    else:\n",
    "        print(\"[red]Can't persist embeddings in local vector db, ArXiv category not existing[/red]\")\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
