{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Synchronization\n",
    "\n",
    "> Synchronize all latest papers from arXiv with the PDF existing on the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp arxiv_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default .dotenv file for running the test upon the execution of this notebook. You can remove `'../.dotenv'` if you already configured your `.env` file locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "load_dotenv('../.dotenv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "import concurrent.futures\n",
    "import feedparser\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from pypdf import PdfReader\n",
    "from readnext.arxiv_categories import exists\n",
    "from rich import print\n",
    "from rich.progress import Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get daily papers from arXiv\n",
    "\n",
    "The first step is to get all the new papers from arXiv. This is done by using their daily RSS feed for any given top, or sub, category. We parse the RSS feed to extract all new papers from the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_arxiv_pdfs_url(category: str) -> list:\n",
    "    \"Get all the papers refferenced in the daily RSS feed on ArXiv for input 'category'.\"\n",
    "    if exists(category):\n",
    "        feed = feedparser.parse('http://arxiv.org/rss/' + category)\n",
    "\n",
    "        # get the URL of the PDF file of each paper from the RSS feed\n",
    "        URLs = []\n",
    "        for entry in feed.entries:\n",
    "            URLs.append(entry.link)\n",
    "\n",
    "        # return the list of the URL of the PDF file of the paper\n",
    "        return URLs\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Docs Path\n",
    "\n",
    "The synchronization process incurs downloading all the new PDF file for a category on the local file system. The `DOCS_PATH` environment variable specify where the documents will be saved.\n",
    "\n",
    "The new PDF files will be saved in the `DOCS_PATH/[category]/` folder. The `get_docs_path` function returns the path string to the folder for a given category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_docs_path(category: str) -> str:\n",
    "    \"Generate the proper docs path from a category ID\"\n",
    "    return os.environ.get('DOCS_PATH').rstrip('/') + '/' + category + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_docs_path(\"cs\") == os.environ.get('DOCS_PATH').rstrip('/') + '/' + \"cs\" + '/'\n",
    "assert get_docs_path(\"cs.AI\") == os.environ.get('DOCS_PATH').rstrip('/') + '/' + \"cs.AI\" + '/'\n",
    "assert get_docs_path(\"cs.FOO\") != os.environ.get('DOCS_PATH').rstrip('/') + '/' + \"cs.AI\" + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete broken PDF files\n",
    "\n",
    "In rare occurences, it may happen that the downloaded PDF file are broken. The current process to detect and fix this issue is to try to open every downloaded PDF with `PdfReader`. If an exception is thrown, then we simply delete the file and move on. \n",
    "\n",
    "In the future, we will have to replace that mechanism with a better fail over mechanism.\n",
    "\n",
    "The side effect of running `delete_broken_pdf` is that it may delete broken PDF files from the file system for a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def delete_broken_pdf(category: str):\n",
    "    \"\"\"Detect and delete broken PDF files.\n",
    "       TODO Next iteration needs a better fail over with retry when PDF files are broken from a download.\n",
    "    \"\"\"\n",
    "\n",
    "    docs_path = get_docs_path(category)\n",
    "\n",
    "    # get the list of the PDF files\n",
    "    pdf_files = os.listdir(docs_path)\n",
    "\n",
    "    # try to open each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            with open (docs_path + pdf_file, 'rb') as pdf_file_obj:\n",
    "                PdfReader(pdf_file_obj)\n",
    "        except Exception as exc:\n",
    "            # delete the PDF file if it is broken\n",
    "            os.remove(docs_path + pdf_file)\n",
    "            print('[italic yellow]Broken file deleted: ' + docs_path + pdf_file + '   [' + str(exc) + '][/italic yellow]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "from os.path import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "from unittest.mock import patch\n",
    "\n",
    "with patch.dict('os.environ', {'DOCS_PATH': 'docs/'}):\n",
    "    # your code that uses os.environ.get('DOCS_PATH') here\n",
    "\n",
    "    # count the current number of PDF files in docs_path\n",
    "    docs_path = get_docs_path(\"cs\")\n",
    "    os.makedirs(docs_path, exist_ok=True)\n",
    "    pdf_files = os.listdir(docs_path)\n",
    "    pdf_files_count_before = len(pdf_files)\n",
    "\n",
    "    # create and empty PDF file at docs_path to produce an invalid PDF file\n",
    "    docs_path = get_docs_path(\"cs\")\n",
    "    open(docs_path + \"foo.pdf\", 'a').close()\n",
    "\n",
    "    # run delete_broken_pdf\n",
    "    delete_broken_pdf(\"cs\")\n",
    "\n",
    "    # count the number of PDF files in docs_path\n",
    "    pdf_files = os.listdir(docs_path)\n",
    "    pdf_files_count_after = len(pdf_files)\n",
    "\n",
    "    assert pdf_files_count_after == pdf_files_count_before\n",
    "\n",
    "    # cleanup\n",
    "    rmtree(split(split(docs_path)[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize with arXiv\n",
    "\n",
    "The `sync_arxiv` function is the main function that will synchronize the local file system with arXiv. It will download all the new PDF files from arXiv and delete any broken PDF files. It downloads three PDF files concurrently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sync_arxiv(category: str):\n",
    "    \"\"\"Synchronize all latest arxiv papers for `category`.\n",
    "       Concurrently download three PDF files from ArXiv. \n",
    "       The PDF files will be saved in the `DOCS_PATH` folder \n",
    "       under the category's sub-folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # create the \"docs\" folder if it does not exist\n",
    "    docs_path = get_docs_path(category)\n",
    "\n",
    "    if not os.path.exists(docs_path):\n",
    "        print(\"[italic yellow]Creating directory '\" + docs_path + \"'[/italic yellow]\")\n",
    "        os.makedirs(docs_path)\n",
    "\n",
    "    with Progress() as progress:\n",
    "\n",
    "        urls = get_arxiv_pdfs_url(category)\n",
    "\n",
    "        task = progress.add_task(\"[cyan]Downloading papers...\", total=len(urls))\n",
    "\n",
    "        def progress_indicator(future):\n",
    "            \"Local progress indicator callback for the concurrent.futures module.\"\n",
    "            if not progress.finished:\n",
    "                progress.update(task, advance=1)\n",
    "\n",
    "        # download each PDF from the URL list into the local \"docs\" folder\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            for url in urls:\n",
    "                # get the name of the PDF file\n",
    "                paper_name = url.split('/')[-1]\n",
    "\n",
    "                # skip if the paper is already downloaded\n",
    "                if os.path.exists(docs_path + paper_name + '.pdf'):\n",
    "                    if not progress.finished:\n",
    "                        progress.update(task, advance=1)\n",
    "                    continue\n",
    "\n",
    "                # transform the URL to get the URL of the PDF file\n",
    "                url = re.sub('abs', 'pdf', url) + '.pdf'\n",
    "\n",
    "                # download the PDF file\n",
    "                futures = [executor.submit(urllib.request.urlretrieve, url, docs_path + paper_name + '.pdf')]\n",
    "\n",
    "                # register the progress indicator callback for each of the future\n",
    "                for future in futures:\n",
    "                    future.add_done_callback(progress_indicator)\n",
    "\n",
    "    # delete possible broken PDF files during download.\n",
    "    # a better detection & fallback mechanism should be implemented in the future.\n",
    "    delete_broken_pdf(category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
